{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/quaternion_neurons/blob/main/train_quaternion_algebras_resnet18_cifar10_cifar100_svhn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFn4lZebEm29",
        "outputId": "bdcf02f5-574e-406f-a770-7d79b01cbf1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/TParcollet/Quaternion-Neural-Networks.git\n",
            "  Cloning https://github.com/TParcollet/Quaternion-Neural-Networks.git to /tmp/pip-req-build-dw6yhrw6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/TParcollet/Quaternion-Neural-Networks.git /tmp/pip-req-build-dw6yhrw6\n",
            "  Resolved https://github.com/TParcollet/Quaternion-Neural-Networks.git to commit f8de5d5e5a3f9c694a0d62cffc64ec4ccdffd1bc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Pytorch-QNN\n",
            "  Building wheel for Pytorch-QNN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pytorch-QNN: filename=Pytorch_QNN-1-py3-none-any.whl size=21516 sha256=6501ceec8bbeb71b845fd40cb158133588ece01e0e78cfcedfa622a0082cff88\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vgbtv5nx/wheels/55/78/10/235c627601beea89722aa1507e19d17aae118511b3de0799b6\n",
            "Successfully built Pytorch-QNN\n",
            "Installing collected packages: Pytorch-QNN\n",
            "Successfully installed Pytorch-QNN-1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/TParcollet/Quaternion-Neural-Networks.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9jfw2vhJ9KpU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.nn import BatchNorm2d\n",
        "from torch.nn import Parameter\n",
        "from core_qnn.quaternion_layers import RandomState\n",
        "from core_qnn.quaternion_layers import quaternion_init\n",
        "from core_qnn.quaternion_layers import affect_init\n",
        "from core_qnn.quaternion_ops import unitary_init\n",
        "from core_qnn.quaternion_ops import random_init\n",
        "from core_qnn.quaternion_ops import affect_init_conv\n",
        "from core_qnn.quaternion_layers import get_kernel_and_weight_shape\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypercomplex fully-connected and convolutional layers (TESSARINE)"
      ],
      "metadata": {
        "id": "1aJv6-C-J8RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quaternion_conv(input, r_weight, i_weight, j_weight, k_weight, bias, stride,\n",
        "                    padding, groups, dilatation, algebra='quaternion'):\n",
        "    \"\"\"\n",
        "    Applies a quaternion convolution to the incoming data:\n",
        "\n",
        "    Available algebras:\n",
        "    quat\n",
        "    \"\"\"\n",
        "    if algebra == 'quaternion':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=1)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=1)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=1)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=1)\n",
        "    elif algebra == 'rq':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, j_weight, -k_weight], dim=1)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, k_weight, j_weight], dim=1)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  -k_weight, r_weight, -i_weight], dim=1)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  j_weight, i_weight, r_weight], dim=1)\n",
        "    elif algebra == 'tessarion':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, i_weight, -j_weight, -k_weight], dim=1)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, -j_weight], dim=1)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=1)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  j_weight, i_weight, r_weight], dim=1)\n",
        "    else: # HCA4\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, k_weight], dim=1)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=1)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=1)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  -j_weight, -i_weight, r_weight], dim=1)\n",
        "\n",
        "\n",
        "    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=0)\n",
        "\n",
        "    if   input.dim() == 3:\n",
        "        convfunc = F.conv1d\n",
        "    elif input.dim() == 4:\n",
        "        convfunc = F.conv2d\n",
        "    elif input.dim() == 5:\n",
        "        convfunc = F.conv3d\n",
        "    else:\n",
        "        raise Exception(\"The convolutional input is either 3, 4 or 5 dimensions.\"\n",
        "                        \" input.dim = \" + str(input.dim()))\n",
        "\n",
        "    return convfunc(input, cat_kernels_4_quaternion, bias, stride, padding, dilatation, groups)"
      ],
      "metadata": {
        "id": "91wNaZBOJ7Zn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quaternion_linear(input, r_weight, i_weight, j_weight, k_weight, bias=True, algebra='quaternion'):\n",
        "    \"\"\"\n",
        "    Applies a quaternion linear transformation to the incoming data:\n",
        "    It is important to notice that the forward phase of a QNN is defined\n",
        "    as W * Inputs (with * equal to the Hamilton product). The constructed\n",
        "    cat_kernels_4_quaternion is a modified version of the quaternion representation\n",
        "    so when we do torch.mm(Input,W) it's equivalent to W * Inputs.\n",
        "    \"\"\"\n",
        "    if algebra == 'quaternion':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=0)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=0)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=0)\n",
        "    elif algebra == 'rq':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, j_weight, -k_weight], dim=0)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, k_weight, j_weight], dim=0)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  -k_weight, r_weight, -i_weight], dim=0)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  j_weight, i_weight, r_weight], dim=0)\n",
        "    elif algebra == 'tessarion':\n",
        "      cat_kernels_4_r = torch.cat([r_weight, i_weight, -j_weight, -k_weight], dim=0)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, -j_weight], dim=0)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  j_weight, i_weight, r_weight], dim=0)\n",
        "    else: # HCA4\n",
        "      cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, k_weight], dim=0)\n",
        "      cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=0)\n",
        "      cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "      cat_kernels_4_k = torch.cat([k_weight,  -j_weight, -i_weight, r_weight], dim=0)\n",
        "\n",
        "    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=1)\n",
        "\n",
        "    if input.dim() == 2 :\n",
        "\n",
        "        if bias is not None:\n",
        "            return torch.addmm(bias, input, cat_kernels_4_quaternion)\n",
        "        else:\n",
        "            return torch.mm(input, cat_kernels_4_quaternion)\n",
        "    else:\n",
        "        output = torch.matmul(input, cat_kernels_4_quaternion)\n",
        "        if bias is not None:\n",
        "            return output+bias\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "FiasMLlhKkae"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionConv(Module):\n",
        "    r\"\"\"Applies a Quaternion Convolution to the incoming data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 dilatation=1, padding=0, groups=1, bias=True, init_criterion='glorot',\n",
        "                 weight_init='quaternion', seed=None, operation='convolution2d', rotation=False, quaternion_format=True, scale=False, algebra='quaternion'):\n",
        "\n",
        "        super(QuaternionConv, self).__init__()\n",
        "\n",
        "        self.in_channels       = in_channels  // 4\n",
        "        self.out_channels      = out_channels // 4\n",
        "        self.stride            = stride\n",
        "        self.padding           = padding\n",
        "        self.groups            = groups\n",
        "        self.dilatation        = dilatation\n",
        "        self.init_criterion    = init_criterion\n",
        "        self.weight_init       = weight_init\n",
        "        self.seed              = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng               = RandomState(self.seed)\n",
        "        self.operation         = operation\n",
        "        self.rotation          = rotation\n",
        "        self.quaternion_format = quaternion_format\n",
        "        self.winit             =    {'quaternion': quaternion_init,\n",
        "                                     'unitary'   : unitary_init,\n",
        "                                     'random'    : random_init}[self.weight_init]\n",
        "        self.scale             = scale\n",
        "        self.algebra           = algebra\n",
        "\n",
        "\n",
        "        (self.kernel_size, self.w_shape) = get_kernel_and_weight_shape( self.operation,\n",
        "            self.in_channels, self.out_channels, kernel_size )\n",
        "\n",
        "        self.r_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.i_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.j_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.k_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "\n",
        "        if self.scale:\n",
        "            self.scale_param  = Parameter(torch.Tensor(self.r_weight.shape))\n",
        "        else:\n",
        "            self.scale_param  = None\n",
        "\n",
        "        if self.rotation:\n",
        "            self.zero_kernel = Parameter(torch.zeros(self.r_weight.shape), requires_grad=False)\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        affect_init_conv(self.r_weight, self.i_weight, self.j_weight, self.k_weight,\n",
        "                    self.kernel_size, self.winit, self.rng, self.init_criterion)\n",
        "        if self.scale_param is not None:\n",
        "            torch.nn.init.xavier_uniform_(self.scale_param.data)\n",
        "        if self.bias is not None:\n",
        "           self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.rotation:\n",
        "            return quaternion_conv_rotation(input, self.zero_kernel, self.r_weight, self.i_weight, self.j_weight,\n",
        "                self.k_weight, self.bias, self.stride, self.padding, self.groups, self.dilatation,\n",
        "                self.quaternion_format, self.scale_param, algebra=self.algebra)\n",
        "        else:\n",
        "            return quaternion_conv(input, self.r_weight, self.i_weight, self.j_weight,\n",
        "                self.k_weight, self.bias, self.stride, self.padding, self.groups, self.dilatation, algebra=self.algebra)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_channels='      + str(self.in_channels) \\\n",
        "            + ', out_channels='   + str(self.out_channels) \\\n",
        "            + ', bias='           + str(self.bias is not None) \\\n",
        "            + ', kernel_size='    + str(self.kernel_size) \\\n",
        "            + ', stride='         + str(self.stride) \\\n",
        "            + ', padding='        + str(self.padding) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init='    + str(self.weight_init) \\\n",
        "            + ', seed='           + str(self.seed) \\\n",
        "            + ', rotation='       + str(self.rotation) \\\n",
        "            + ', q_format='       + str(self.quaternion_format) \\\n",
        "            + ', operation='      + str(self.operation) + ')'"
      ],
      "metadata": {
        "id": "oQPNf6EdKkdW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionLinear(Module):\n",
        "    r\"\"\"Applies a quaternion linear transformation to the incoming data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 init_criterion='he', weight_init='quaternion',\n",
        "                 seed=None, algebra='quaternion'):\n",
        "\n",
        "        super(QuaternionLinear, self).__init__()\n",
        "        self.in_features  = in_features//4\n",
        "        self.out_features = out_features//4\n",
        "        self.algebra = algebra\n",
        "\n",
        "        self.r_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.i_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.j_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.k_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias     = Parameter(torch.Tensor(self.out_features*4))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.init_criterion = init_criterion\n",
        "        self.weight_init    = weight_init\n",
        "        self.seed           = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng            = RandomState(self.seed)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        winit = {'quaternion': quaternion_init,\n",
        "                 'unitary': unitary_init}[self.weight_init]\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.fill_(0)\n",
        "        affect_init(self.r_weight, self.i_weight, self.j_weight, self.k_weight, winit,\n",
        "                    self.rng, self.init_criterion)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See the autograd section for explanation of what happens here.\n",
        "        if input.dim() == 3:\n",
        "            T, N, C = input.size()\n",
        "            input  = input.view(T * N, C)\n",
        "            output = quaternion_linear(input, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias, self.algebra)\n",
        "            output = output.view(T, N, output.size(1))\n",
        "        elif input.dim() == 2:\n",
        "            output = quaternion_linear(input, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias, self.algebra)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_features=' + str(self.in_features) \\\n",
        "            + ', out_features=' + str(self.out_features) \\\n",
        "            + ', bias=' + str(self.bias is not None) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init=' + str(self.weight_init) \\\n",
        "            + ', seed=' + str(self.seed) + ')'"
      ],
      "metadata": {
        "id": "5QM5tDg7J4Je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKks01hTCa5l"
      },
      "source": [
        "### Blocks of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZYu8xpYR9bqX"
      },
      "outputs": [],
      "source": [
        "class QBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, algebra='quaternion'):\n",
        "        super(QBasicBlock, self).__init__()\n",
        "        self.conv1 = QuaternionConv(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, algebra=algebra)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = QuaternionConv(planes, planes, kernel_size=3, stride=1, padding=1, bias=False, algebra=algebra)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                QuaternionConv(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False, algebra=algebra),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v5HwRxMp9gbX"
      },
      "outputs": [],
      "source": [
        "class QBottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, algebra='quaternion'):\n",
        "        super(QBottleneck, self).__init__()\n",
        "        self.conv1 = QuaternionConv(in_planes, planes, kernel_size=1, bias=False, algebra=algebra)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = QuaternionConv(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, algebra=algebra)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = QuaternionConv(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False, algebra=algebra)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.QuaternionConv(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False, algebra=algebra),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPp5hYfbCWhH"
      },
      "source": [
        "### The model (Real resnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LZmrGGI9k98"
      },
      "outputs": [],
      "source": [
        "class QResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=12, algebra='quaternion'):\n",
        "        super(QResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.algebra = algebra\n",
        "\n",
        "        self.conv1 = QuaternionConv(4, 64, kernel_size=3, stride=1, padding=1, bias=False, algebra = self.algebra)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = QuaternionLinear(512*block.expansion, num_classes, algebra = self.algebra)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, algebra=self.algebra))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        zeros = torch.zeros(x.shape[0], \n",
        "                            1, \n",
        "                            x.shape[2], \n",
        "                            x.shape[3], dtype=x.dtype, device=x.device)\n",
        "        x = torch.cat((zeros, x), dim=1)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = out[:, 2:]\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vXUt5jbCQfv"
      },
      "source": [
        "### Training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mMr29xai9o8k"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(net, criterion, trainloader, optimizer, device, epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        #print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laEOjmLJCN53"
      },
      "source": [
        "### Testing procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BYoM7lBCBTYD"
      },
      "outputs": [],
      "source": [
        "def test(net, testloader, device, criterion, epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        #print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMRq-0cHCK7d"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuJZNjC4BXsD"
      },
      "outputs": [],
      "source": [
        "def run_round(algebra='quaternion', dataset = torchvision.datasets.CIFAR10, network=[2, 2, 2, 2]):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  best_acc = 0\n",
        "  start_epoch = 0\n",
        "\n",
        "  # Data\n",
        "  # print('==> Preparing data..')\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "  ])\n",
        "\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "  ])\n",
        "\n",
        "  trainset = dataset(root='./data', train=True, download=True, transform=transform_train)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "  testset = dataset(root='./data', train=False, download=True, transform=transform_test)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "  # Model\n",
        "  # print('==> Building model..')\n",
        "  num_classes = 0\n",
        "  if dataset == torchvision.datasets.CIFAR10:\n",
        "    num_classes = 12\n",
        "  elif dataset == torchvision.datasets.CIFAR100:\n",
        "    num_classes = 100\n",
        "  elif dataset == torchvision.datasets.SVHN:\n",
        "    num_classes = 12\n",
        "  net = QResNet(QBasicBlock, network)\n",
        "  net = net.to(device)\n",
        "\n",
        "  if device == 'cuda':\n",
        "      net = torch.nn.DataParallel(net)\n",
        "      cudnn.benchmark = True\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch+1):\n",
        "    train(net, criterion, trainloader, optimizer, device, epoch)\n",
        "    test(net, testloader, device, criterion, epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "  # Convert testset to appropriate format\n",
        "  test_labels = []\n",
        "  predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for images, labels in testloader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "          test_labels.extend(labels.cpu().numpy().tolist())\n",
        "          predictions.extend(predicted.cpu().numpy().tolist())\n",
        "\n",
        "  cr = classification_report(test_labels, predictions, target_names=classes, digits=3)\n",
        "  \n",
        "  # Display the classification report\n",
        "  print('Algebra: {}'.format(algebra))\n",
        "  print('Dataset: {}'.format(dataset))\n",
        "  print('Network: {}'.format(network))\n",
        "  print(\"Classification Report:\")\n",
        "  print(cr)\n",
        "\n",
        "  num_classes = 0\n",
        "if dataset == torchvision.datasets.CIFAR10:\n",
        "  num_classes = 12\n",
        "elif dataset == torchvision.datasets.CIFAR100:\n",
        "  num_classes = 100\n",
        "elif dataset == torchvision.datasets.SVHN:\n",
        "  num_classes = 12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(torchvision.datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ReJBjWUSmpm",
        "outputId": "42d437c7-7b40-4220-f228-d9670992d8fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CIFAR10',\n",
              " 'CIFAR100',\n",
              " 'CLEVRClassification',\n",
              " 'CREStereo',\n",
              " 'Caltech101',\n",
              " 'Caltech256',\n",
              " 'CarlaStereo',\n",
              " 'CelebA',\n",
              " 'Cityscapes',\n",
              " 'CocoCaptions',\n",
              " 'CocoDetection',\n",
              " 'Country211',\n",
              " 'DTD',\n",
              " 'DatasetFolder',\n",
              " 'EMNIST',\n",
              " 'ETH3DStereo',\n",
              " 'EuroSAT',\n",
              " 'FER2013',\n",
              " 'FGVCAircraft',\n",
              " 'FakeData',\n",
              " 'FallingThingsStereo',\n",
              " 'FashionMNIST',\n",
              " 'Flickr30k',\n",
              " 'Flickr8k',\n",
              " 'Flowers102',\n",
              " 'FlyingChairs',\n",
              " 'FlyingThings3D',\n",
              " 'Food101',\n",
              " 'GTSRB',\n",
              " 'HD1K',\n",
              " 'HMDB51',\n",
              " 'INaturalist',\n",
              " 'ImageFolder',\n",
              " 'ImageNet',\n",
              " 'InStereo2k',\n",
              " 'KMNIST',\n",
              " 'Kinetics',\n",
              " 'Kitti',\n",
              " 'Kitti2012Stereo',\n",
              " 'Kitti2015Stereo',\n",
              " 'KittiFlow',\n",
              " 'LFWPairs',\n",
              " 'LFWPeople',\n",
              " 'LSUN',\n",
              " 'LSUNClass',\n",
              " 'MNIST',\n",
              " 'Middlebury2014Stereo',\n",
              " 'Omniglot',\n",
              " 'OxfordIIITPet',\n",
              " 'PCAM',\n",
              " 'PhotoTour',\n",
              " 'Places365',\n",
              " 'QMNIST',\n",
              " 'RenderedSST2',\n",
              " 'SBDataset',\n",
              " 'SBU',\n",
              " 'SEMEION',\n",
              " 'STL10',\n",
              " 'SUN397',\n",
              " 'SVHN',\n",
              " 'SceneFlowStereo',\n",
              " 'Sintel',\n",
              " 'SintelStereo',\n",
              " 'StanfordCars',\n",
              " 'UCF101',\n",
              " 'USPS',\n",
              " 'VOCDetection',\n",
              " 'VOCSegmentation',\n",
              " 'VisionDataset',\n",
              " 'WIDERFace',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_optical_flow',\n",
              " '_stereo_matching',\n",
              " 'caltech',\n",
              " 'celeba',\n",
              " 'cifar',\n",
              " 'cityscapes',\n",
              " 'clevr',\n",
              " 'coco',\n",
              " 'country211',\n",
              " 'dtd',\n",
              " 'eurosat',\n",
              " 'fakedata',\n",
              " 'fer2013',\n",
              " 'fgvc_aircraft',\n",
              " 'flickr',\n",
              " 'flowers102',\n",
              " 'folder',\n",
              " 'food101',\n",
              " 'gtsrb',\n",
              " 'hmdb51',\n",
              " 'imagenet',\n",
              " 'inaturalist',\n",
              " 'kinetics',\n",
              " 'kitti',\n",
              " 'lfw',\n",
              " 'lsun',\n",
              " 'mnist',\n",
              " 'omniglot',\n",
              " 'oxford_iiit_pet',\n",
              " 'pcam',\n",
              " 'phototour',\n",
              " 'places365',\n",
              " 'rendered_sst2',\n",
              " 'sbd',\n",
              " 'sbu',\n",
              " 'semeion',\n",
              " 'stanford_cars',\n",
              " 'stl10',\n",
              " 'sun397',\n",
              " 'svhn',\n",
              " 'ucf101',\n",
              " 'usps',\n",
              " 'utils',\n",
              " 'video_utils',\n",
              " 'vision',\n",
              " 'voc',\n",
              " 'widerface']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_round(algebra='quaternion', dataset = torchvision.datasets.CIFAR10, network=[2, 2, 2, 2])\n"
      ],
      "metadata": {
        "id": "Swd05m37Q-8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 0\n",
        "if dataset == torchvision.datasets.CIFAR10:\n",
        "  num_classes = 12\n",
        "elif dataset == torchvision.datasets.CIFAR100:\n",
        "  num_classes = 100\n",
        "elif dataset == torchvision.datasets.SVHN:\n",
        "  num_classes = 12"
      ],
      "metadata": {
        "id": "m6fzZuuhQ_Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVv2fLmXPZSq"
      },
      "outputs": [],
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(net, input_size = (3, 32, 32))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVr0AIJS7DdIKDg7nSTlIN",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}